{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-yv-TS5Dw6gK"
      },
      "source": [
        "# Lab-03 Q1 AlexNet\n",
        "\n",
        "Please run the code with \"VScode-devcontainer\".\n",
        "\n",
        "It is easier to use Git in local.  \n",
        "Also, google colab is slower than my laptop sometimes. ( i7-GEN-12 + RTX-3070-Ti + DDR4-40-GB )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ckgngt4Aw6gN"
      },
      "outputs": [],
      "source": [
        "# install requirements\n",
        "#\n",
        "# !pip install pytorchcv torchinfo\n",
        "# !wget -P data/cifar10_1 https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_labels.npy\n",
        "# !wget -P data/cifar10_1 https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_data.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "nN5h5ZUKw6gO"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from pytorchcv.model_provider import get_model\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import Cifar10_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fORhoU1hw6gP",
        "outputId": "734e35db-1110-404e-cc09-fa990b54bf57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# define some hyper parameters\n",
        "DATA_PATH = './data'\n",
        "\n",
        "# change these hyper parameter if needed\n",
        "BATCH_SIZE = 32\n",
        "EPOCH = 10\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# check device (CPU, GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "u-O9TQUrw6gP"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# augment data here\n",
        "# https://pytorch.org/vision/master/transforms.html\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-3IQxW8w6gQ",
        "outputId": "6e80183a-6aa0-4d71-931c-15db19ffe41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(2000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# load dataset : CIFAR-10\n",
        "\n",
        "trainset   = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset_1  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testset_2  = Cifar10_1(root='./data/cifar10_1/', transform=transform)\n",
        "\n",
        "print(trainset.data.shape)\n",
        "print(testset_1.data.shape)\n",
        "print(testset_2.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reference: https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "bZDX4FR_w6gR"
      },
      "outputs": [],
      "source": [
        "# Get model\n",
        "model_name = \"AlexNet\"\n",
        "model = AlexNet(NUM_CLASSES).to(device)\n",
        "\n",
        "# Choose loss function\n",
        "LOSS_FUNCTION = \"CrossEntropy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model parameters: model_1.pth\n"
          ]
        }
      ],
      "source": [
        "# Load model parameter\n",
        "is_load_model_param = True\n",
        "load_model_param_UUID = 1\n",
        "\n",
        "# Reference: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "if is_load_model_param:\n",
        "    model.load_state_dict(torch.load(f\"./model/model_{load_model_param_UUID}.pth\"))\n",
        "    model.eval()\n",
        "    print(f\"Loaded model parameters: model_{load_model_param_UUID}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LigRB4biw6gR",
        "outputId": "7ec66e10-07fb-41d6-de7e-93c7f49127a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "AlexNet                                  [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 256, 6, 6]            --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n",
              "│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n",
              "│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n",
              "│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n",
              "│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n",
              "│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n",
              "│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n",
              "│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n",
              "│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n",
              "│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n",
              "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n",
              "│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n",
              "│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n",
              "├─Sequential: 1-3                        [1, 10]                   --\n",
              "│    └─Dropout: 2-14                     [1, 9216]                 --\n",
              "│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n",
              "│    └─ReLU: 2-16                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-17                     [1, 4096]                 --\n",
              "│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-19                        [1, 4096]                 --\n",
              "│    └─Linear: 2-20                      [1, 10]                   40,970\n",
              "==========================================================================================\n",
              "Total params: 57,044,810\n",
              "Trainable params: 57,044,810\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 710.63\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 3.95\n",
              "Params size (MB): 228.18\n",
              "Estimated Total Size (MB): 232.73\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, input_size=(1, 3, 224, 224), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KtDslt2rw6gS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'UUID': 1, 'BATCH_SIZE': 32, 'EPOCH': 10, 'MODEL_NAME': 'AlexNet', 'LOSS_FUNCTION': 'CrossEntropy', 'DEVICE': 'cuda'}\n"
          ]
        }
      ],
      "source": [
        "# version control\n",
        "UUID = 1\n",
        "\n",
        "hyperparameter_log = {\n",
        "    \"UUID\": UUID,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"EPOCH\": EPOCH,\n",
        "    \"MODEL_NAME\": model_name,\n",
        "    \"LOSS_FUNCTION\": LOSS_FUNCTION,\n",
        "    \"DEVICE\": device.type\n",
        "}\n",
        "\n",
        "print(hyperparameter_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kXh6Z-gPw6gS"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "trainloader  = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "testloader_1 = DataLoader(testset_1, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader_2 = DataLoader(testset_2, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9Vd2JLctw6gS"
      },
      "outputs": [],
      "source": [
        "# define loss function\n",
        "# https://blog.csdn.net/weixin_36670529/article/details/105670337\n",
        "if LOSS_FUNCTION == \"CrossEntropy\":\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "elif LOSS_FUNCTION == \"MSE\":\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "# or define your own loss function here\n",
        "# https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
        "# https://rowantseng.medium.com/pytorch-%E8%87%AA%E5%AE%9A%E7%BE%A9%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-custom-loss-c12e8741968b\n",
        "# https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "# 😂\n",
        "\n",
        "# Do not modify this\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iM4dqEDaw6gS",
        "outputId": "9a3393fd-c86b-433d-c2d3-c9cbf8f08a24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [0], loss: 0.8261, acc: 0.7640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [1], loss: 0.7729, acc: 0.7827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [2], loss: 0.7254, acc: 0.8017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [3], loss: 0.6799, acc: 0.8192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [4], loss: 0.6365, acc: 0.8330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [5], loss: 0.6023, acc: 0.8445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [6], loss: 0.5642, acc: 0.8572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [7], loss: 0.5276, acc: 0.8723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [8], loss: 0.5038, acc: 0.8791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:48<00:00, 32.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [9], loss: 0.4707, acc: 0.8891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "def train(e):\n",
        "    model.train()\n",
        "    num_data = 0\n",
        "    correct = 0\n",
        "    loss_all = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(tqdm(trainloader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(x)\n",
        "\n",
        "        # compute loss here\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        # L2 Regularization\n",
        "        # Reference: https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "        l2_lambda = 0.00005\n",
        "        l2_norm = sum(param.pow(2.0).sum() for param in model.parameters())\n",
        "        loss += l2_lambda * l2_norm\n",
        "\n",
        "        # back prop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # log\n",
        "        num_data += y.size(0)\n",
        "        loss_all += loss.item()\n",
        "        pred = outputs.data.max(1)[1]\n",
        "        correct += pred.eq(y.view(-1)).sum().item()\n",
        "\n",
        "    print(f\"epoch: [{e}], loss: {loss_all/len(trainloader):.4f}, acc: {correct/num_data:.4f}\")\n",
        "\n",
        "\n",
        "# start training\n",
        "for e in range(EPOCH):\n",
        "    train(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tkR2B0ow6gT",
        "outputId": "c89f9258-099e-4290-c1a5-2727d712fff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "on testset 1: loss: 0.5444, acc: 0.8234\n",
            "on testset 2: loss: 0.9866, acc: 0.6960\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "def test(model, test_loader, loss_fun, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    targets = []\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device).long()\n",
        "\n",
        "        targets.append(target.detach().cpu().numpy())\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        test_loss += loss_fun(output, target).item()\n",
        "        pred = output.data.max(1)[1]\n",
        "\n",
        "        correct += pred.eq(target.view(-1)).sum().item()\n",
        "\n",
        "    return test_loss/len(test_loader), correct /len(test_loader.dataset)\n",
        "\n",
        "\n",
        "loss, acc = test(model, testloader_1, criterion, device)\n",
        "print(f\"on testset 1: loss: {loss:.4f}, acc: {acc:.4f}\")\n",
        "\n",
        "loss, acc = test(model, testloader_2, criterion, device)\n",
        "print(f\"on testset 2: loss: {loss:.4f}, acc: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), f'./model/model_{UUID}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "vj_Q4AsOw6gT"
      },
      "outputs": [],
      "source": [
        "# record the results to a log file (e.g google sheet, )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
