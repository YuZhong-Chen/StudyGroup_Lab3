{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-yv-TS5Dw6gK"
      },
      "source": [
        "# Lab-03 Q1 AlexNet\n",
        "\n",
        "Please run the code with \"VScode-devcontainer\".\n",
        "\n",
        "( It is easier to use Git in local. )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "id": "ckgngt4Aw6gN"
      },
      "outputs": [],
      "source": [
        "# install requirements\n",
        "\n",
        "# !wget -P data/cifar10_1 https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_labels.npy\n",
        "# !wget -P data/cifar10_1 https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_data.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "nN5h5ZUKw6gO"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from pytorchcv.model_provider import get_model\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import Cifar10_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fORhoU1hw6gP",
        "outputId": "734e35db-1110-404e-cc09-fa990b54bf57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# define some hyper parameters\n",
        "DATA_PATH = './data'\n",
        "\n",
        "# change these hyper parameter if needed\n",
        "BATCH_SIZE = 32\n",
        "EPOCH = 10\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# check device (CPU, GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "id": "u-O9TQUrw6gP"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# augment data here\n",
        "# https://pytorch.org/vision/master/transforms.html\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    # add augmentation here...\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-3IQxW8w6gQ",
        "outputId": "6e80183a-6aa0-4d71-931c-15db19ffe41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(2000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "\n",
        "# cifar10\n",
        "trainset   = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset_1  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testset_2  = Cifar10_1(root='./data/cifar10_1/', transform=transform)\n",
        "print(trainset.data.shape)\n",
        "print(testset_1.data.shape)\n",
        "print(testset_2.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "id": "0GKxgkZsw6gQ"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# modify your training data here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "JLVSNOPQw6gR"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# split your training data if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "bZDX4FR_w6gR"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# select a model you want (small one or large one)\n",
        "# https://github.com/osmr/imgclsmob/blob/master/pytorch/README.md\n",
        "model_name = 'nin'\n",
        "# model_name = 'densenet100_k24'\n",
        "# model_name = 'preresnet56'\n",
        "model = get_model(name = model_name + '_cifar10', pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "# choose loss function\n",
        "LOSS_FUNCTION = \"CrossEntropy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LigRB4biw6gR",
        "outputId": "7ec66e10-07fb-41d6-de7e-93c7f49127a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CIFARNIN                                 [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 192, 8, 8]            --\n",
              "│    └─Sequential: 2-1                   [1, 96, 32, 32]           --\n",
              "│    │    └─NINConv: 3-1                 [1, 192, 32, 32]          14,592\n",
              "│    │    └─NINConv: 3-2                 [1, 160, 32, 32]          30,880\n",
              "│    │    └─NINConv: 3-3                 [1, 96, 32, 32]           15,456\n",
              "│    └─Sequential: 2-2                   [1, 192, 16, 16]          --\n",
              "│    │    └─MaxPool2d: 3-4               [1, 96, 16, 16]           --\n",
              "│    │    └─Dropout: 3-5                 [1, 96, 16, 16]           --\n",
              "│    │    └─NINConv: 3-6                 [1, 192, 16, 16]          460,992\n",
              "│    │    └─NINConv: 3-7                 [1, 192, 16, 16]          37,056\n",
              "│    │    └─NINConv: 3-8                 [1, 192, 16, 16]          37,056\n",
              "│    └─Sequential: 2-3                   [1, 192, 8, 8]            --\n",
              "│    │    └─AvgPool2d: 3-9               [1, 192, 8, 8]            --\n",
              "│    │    └─Dropout: 3-10                [1, 192, 8, 8]            --\n",
              "│    │    └─NINConv: 3-11                [1, 192, 8, 8]            331,968\n",
              "│    │    └─NINConv: 3-12                [1, 192, 8, 8]            37,056\n",
              "├─Sequential: 1-2                        [1, 10, 1, 1]             --\n",
              "│    └─NINConv: 2-4                      [1, 10, 8, 8]             --\n",
              "│    │    └─Conv2d: 3-13                 [1, 10, 8, 8]             1,930\n",
              "│    │    └─ReLU: 3-14                   [1, 10, 8, 8]             --\n",
              "│    └─AvgPool2d: 2-5                    [1, 10, 1, 1]             --\n",
              "==========================================================================================\n",
              "Total params: 966,986\n",
              "Trainable params: 966,986\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 223.12\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 5.05\n",
              "Params size (MB): 3.87\n",
              "Estimated Total Size (MB): 8.93\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 356,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, input_size=(1, 3, 32, 32), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {
        "id": "KtDslt2rw6gS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'UUID': 1, 'BATCH_SIZE': 32, 'EPOCH': 10, 'MODEL_NAME': 'nin', 'LOSS_FUNCTION': 'CrossEntropy', 'DEVICE': 'cuda'}\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "# version control\n",
        "UUID = 1\n",
        "\n",
        "hyperparameter_log = {\n",
        "  \"UUID\": UUID,\n",
        "  \"BATCH_SIZE\": BATCH_SIZE,\n",
        "  \"EPOCH\": EPOCH,\n",
        "  \"MODEL_NAME\": model_name,\n",
        "  \"LOSS_FUNCTION\": LOSS_FUNCTION,\n",
        "  \"DEVICE\": device.type\n",
        "}\n",
        "\n",
        "print(hyperparameter_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "id": "kXh6Z-gPw6gS"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "trainloader  = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "testloader_1 = DataLoader(testset_1, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader_2 = DataLoader(testset_2, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "id": "9Vd2JLctw6gS"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# define loss function\n",
        "# https://blog.csdn.net/weixin_36670529/article/details/105670337\n",
        "if LOSS_FUNCTION == \"CrossEntropy\":\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "elif LOSS_FUNCTION == \"MSE\":\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "# or define your own loss function here\n",
        "# https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
        "# https://rowantseng.medium.com/pytorch-%E8%87%AA%E5%AE%9A%E7%BE%A9%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-custom-loss-c12e8741968b\n",
        "# https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "# 😂\n",
        "\n",
        "# Do not modify this\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iM4dqEDaw6gS",
        "outputId": "9a3393fd-c86b-433d-c2d3-c9cbf8f08a24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 116.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [0], loss: 0.3067, acc: 0.9390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 118.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [1], loss: 0.2819, acc: 0.9438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 115.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [2], loss: 0.2699, acc: 0.9472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 117.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [3], loss: 0.2667, acc: 0.9492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 120.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [4], loss: 0.2599, acc: 0.9513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 117.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [5], loss: 0.2597, acc: 0.9511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 119.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [6], loss: 0.2546, acc: 0.9516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 119.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [7], loss: 0.2548, acc: 0.9527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 118.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [8], loss: 0.2528, acc: 0.9535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:13<00:00, 114.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [9], loss: 0.2480, acc: 0.9553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "def train(e):\n",
        "    model.train()\n",
        "    num_data = 0\n",
        "    correct = 0\n",
        "    loss_all = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(tqdm(trainloader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(x)\n",
        "\n",
        "        # compute loss here\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        # L2 Regularization\n",
        "        # Reference: https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "        l2_lambda = 0.00005\n",
        "        l2_norm = sum(param.pow(2.0).sum() for param in model.parameters())\n",
        "        loss += l2_lambda * l2_norm\n",
        "\n",
        "        # back prop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # log\n",
        "        num_data += y.size(0)\n",
        "        loss_all += loss.item()\n",
        "        pred = outputs.data.max(1)[1]\n",
        "        correct += pred.eq(y.view(-1)).sum().item()\n",
        "\n",
        "    print(f\"epoch: [{e}], loss: {loss_all/len(trainloader):.4f}, acc: {correct/num_data:.4f}\")\n",
        "\n",
        "\n",
        "# start training\n",
        "for e in range(EPOCH):\n",
        "    train(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tkR2B0ow6gT",
        "outputId": "c89f9258-099e-4290-c1a5-2727d712fff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "on testset 1: loss: 0.2270, acc: 0.9254\n",
            "on testset 2: loss: 0.4936, acc: 0.8465\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "def test(model, test_loader, loss_fun, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    targets = []\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device).long()\n",
        "\n",
        "        targets.append(target.detach().cpu().numpy())\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        test_loss += loss_fun(output, target).item()\n",
        "        pred = output.data.max(1)[1]\n",
        "\n",
        "        correct += pred.eq(target.view(-1)).sum().item()\n",
        "\n",
        "    return test_loss/len(test_loader), correct /len(test_loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "loss, acc = test(model, testloader_1, criterion, device)\n",
        "print(f\"on testset 1: loss: {loss:.4f}, acc: {acc:.4f}\")\n",
        "\n",
        "loss, acc = test(model, testloader_2, criterion, device)\n",
        "print(f\"on testset 2: loss: {loss:.4f}, acc: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), f'./model/model_{UUID}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "id": "vj_Q4AsOw6gT"
      },
      "outputs": [],
      "source": [
        "# record the results to a log file (e.g google sheet, )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
