{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-yv-TS5Dw6gK"
      },
      "source": [
        "# Dealing with Overfitting\n",
        "\n",
        "In this homework, you are going to address overfitting using various skills. The methods you can try are as follows:\n",
        "\n",
        "1. Change the loss function.\n",
        "2. Change the model architecture.\n",
        "3. Add more data, such as augmentation or splitting the training data.\n",
        "4. ...\n",
        "\n",
        "Additionally, you will learn about logging and version control in this homework.\n",
        "\n",
        "Feel free to ask your friends for assistance and send a message to the TA if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ckgngt4Aw6gN"
      },
      "outputs": [],
      "source": [
        "# install requirements\n",
        "# !wget -P data/cifar10_1 https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_labels.npy\n",
        "# !wget -P data/cifar10_1 https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_data.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nN5h5ZUKw6gO"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from pytorchcv.model_provider import get_model\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "from  utils import Cifar10_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fORhoU1hw6gP",
        "outputId": "734e35db-1110-404e-cc09-fa990b54bf57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# define some hyper parameters\n",
        "DATA_PATH = './data'\n",
        "\n",
        "# change these hyper parameter if needed\n",
        "BATCH_SZIE = 32\n",
        "EPOCH = 10\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# check device (CPU, GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u-O9TQUrw6gP"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# augment data here\n",
        "# https://pytorch.org/vision/master/transforms.htmls\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    # add augmentation here...\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-3IQxW8w6gQ",
        "outputId": "6e80183a-6aa0-4d71-931c-15db19ffe41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(2000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "\n",
        "# cifar10\n",
        "trainset   = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset_1  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testset_2  = Cifar10_1(root='./data/cifar10_1/', transform=transform)\n",
        "print(trainset.data.shape)\n",
        "print(testset_1.data.shape)\n",
        "print(testset_2.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GKxgkZsw6gQ"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# modify your training data here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLVSNOPQw6gR"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# split your training data if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bZDX4FR_w6gR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading /home/yuzhong/.torch/models/nin_cifar10-0743-795b0824.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.175/nin_cifar10-0743-795b0824.pth.zip...\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "# select a model you want (small one or large one)\n",
        "# https://github.com/osmr/imgclsmob/blob/master/pytorch/README.md\n",
        "model_name = 'nin'\n",
        "# model_name = 'densenet100_k24'\n",
        "# model_name = 'preresnet56'\n",
        "model = get_model(name = model_name + '_cifar10', pretrained=True)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LigRB4biw6gR",
        "outputId": "7ec66e10-07fb-41d6-de7e-93c7f49127a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CIFARNIN                                 [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 192, 8, 8]            --\n",
              "│    └─Sequential: 2-1                   [1, 96, 32, 32]           --\n",
              "│    │    └─NINConv: 3-1                 [1, 192, 32, 32]          14,592\n",
              "│    │    └─NINConv: 3-2                 [1, 160, 32, 32]          30,880\n",
              "│    │    └─NINConv: 3-3                 [1, 96, 32, 32]           15,456\n",
              "│    └─Sequential: 2-2                   [1, 192, 16, 16]          --\n",
              "│    │    └─MaxPool2d: 3-4               [1, 96, 16, 16]           --\n",
              "│    │    └─Dropout: 3-5                 [1, 96, 16, 16]           --\n",
              "│    │    └─NINConv: 3-6                 [1, 192, 16, 16]          460,992\n",
              "│    │    └─NINConv: 3-7                 [1, 192, 16, 16]          37,056\n",
              "│    │    └─NINConv: 3-8                 [1, 192, 16, 16]          37,056\n",
              "│    └─Sequential: 2-3                   [1, 192, 8, 8]            --\n",
              "│    │    └─AvgPool2d: 3-9               [1, 192, 8, 8]            --\n",
              "│    │    └─Dropout: 3-10                [1, 192, 8, 8]            --\n",
              "│    │    └─NINConv: 3-11                [1, 192, 8, 8]            331,968\n",
              "│    │    └─NINConv: 3-12                [1, 192, 8, 8]            37,056\n",
              "├─Sequential: 1-2                        [1, 10, 1, 1]             --\n",
              "│    └─NINConv: 2-4                      [1, 10, 8, 8]             --\n",
              "│    │    └─Conv2d: 3-13                 [1, 10, 8, 8]             1,930\n",
              "│    │    └─ReLU: 3-14                   [1, 10, 8, 8]             --\n",
              "│    └─AvgPool2d: 2-5                    [1, 10, 1, 1]             --\n",
              "==========================================================================================\n",
              "Total params: 966,986\n",
              "Trainable params: 966,986\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 223.12\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 5.05\n",
              "Params size (MB): 3.87\n",
              "Estimated Total Size (MB): 8.93\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, input_size=(1, 3, 32, 32), device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ02j9RRw6gS"
      },
      "source": [
        "### Version Control\n",
        "\n",
        "\n",
        "Before starting the training process, it is important to set up version control to track the changes and ensure reproducibility.\n",
        "\n",
        "Here's what you need to do:\n",
        "1. Give the experiment a name or assign it a unique identifier (UUID) to easily identify and reference it later.\n",
        "\n",
        "2. Log all the hyperparameters used for the experiment.\n",
        "    - This includes parameters like learning rate, batch size, optimizer choice, regularization strength, etc.\n",
        "    - Make sure to record these hyperparameters before starting the training process.\n",
        "\n",
        "3. Save the code used for the experiment.\n",
        "    - This ensures that the exact code version used for training is preserved.\n",
        "    - You can create a separate branch or tag in your version control system (e.g., Git) specifically for this experiment.\n",
        "\n",
        "\n",
        "By following these steps, you establish a systematic approach to version control, allowing you to reproduce and compare results accurately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtDslt2rw6gS"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# version control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kXh6Z-gPw6gS"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "trainloader  = DataLoader(trainset, batch_size=BATCH_SZIE, shuffle=True, num_workers=2)\n",
        "testloader_1 = DataLoader(testset_1, batch_size=BATCH_SZIE, shuffle=False, num_workers=2)\n",
        "testloader_2 = DataLoader(testset_2, batch_size=BATCH_SZIE, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9Vd2JLctw6gS"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# define loss function\n",
        "# https://blog.csdn.net/weixin_36670529/article/details/105670337\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# or define your own loss function here\n",
        "# https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
        "# https://rowantseng.medium.com/pytorch-%E8%87%AA%E5%AE%9A%E7%BE%A9%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-custom-loss-c12e8741968b\n",
        "# https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "# 😂\n",
        "\n",
        "# Do not modify this\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iM4dqEDaw6gS",
        "outputId": "9a3393fd-c86b-433d-c2d3-c9cbf8f08a24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 122.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [0], loss: 0.1942, acc: 0.9395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 123.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [1], loss: 0.1668, acc: 0.9450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 123.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [2], loss: 0.1544, acc: 0.9496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 121.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [3], loss: 0.1472, acc: 0.9506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 123.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [4], loss: 0.1418, acc: 0.9528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 123.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [5], loss: 0.1345, acc: 0.9551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 122.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [6], loss: 0.1299, acc: 0.9572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 121.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [7], loss: 0.1238, acc: 0.9582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 122.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [8], loss: 0.1218, acc: 0.9598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 122.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: [9], loss: 0.1182, acc: 0.9600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "def train(e):\n",
        "    model.train()\n",
        "    num_data = 0\n",
        "    correct = 0\n",
        "    loss_all = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(tqdm(trainloader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(x)\n",
        "\n",
        "        # compute loss here\n",
        "        loss = criterion(outputs, y)\n",
        "        # maybe you need to add L2 loss here\n",
        "        # https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "\n",
        "\n",
        "        # back prop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # log\n",
        "        num_data += y.size(0)\n",
        "        loss_all += loss.item()\n",
        "        pred = outputs.data.max(1)[1]\n",
        "        correct += pred.eq(y.view(-1)).sum().item()\n",
        "\n",
        "    print( f'epoch: [{e}], loss: {loss_all/len(trainloader):.4f}, acc: {correct/num_data:.4f}')\n",
        "\n",
        "# start training\n",
        "for e in range(EPOCH):\n",
        "    train(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tkR2B0ow6gT",
        "outputId": "c89f9258-099e-4290-c1a5-2727d712fff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "on testset 1: loss: 0.2312, acc: 0.9243\n",
            "on testset 2: loss: 0.5226, acc: 0.8335\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "def test(model, test_loader, loss_fun, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    targets = []\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device).long()\n",
        "\n",
        "        targets.append(target.detach().cpu().numpy())\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        test_loss += loss_fun(output, target).item()\n",
        "        pred = output.data.max(1)[1]\n",
        "\n",
        "        correct += pred.eq(target.view(-1)).sum().item()\n",
        "\n",
        "    return test_loss/len(test_loader), correct /len(test_loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "loss, acc = test(model, testloader_1, criterion, device)\n",
        "print(f\"on testset 1: loss: {loss:.4f}, acc: {acc:.4f}\")\n",
        "\n",
        "loss, acc = test(model, testloader_2, criterion, device)\n",
        "print(f\"on testset 2: loss: {loss:.4f}, acc: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj_Q4AsOw6gT"
      },
      "outputs": [],
      "source": [
        "# record the results to a log file (e.g google sheet, )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
